{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, kernel_regularizer=None, bias_regularizer=None,\n",
    "                 kernel_constraint=None, bias_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Content Attention mechanism.\n",
    "        Supports Masking.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.GlorotUniform()\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert type(input_shape) == list\n",
    "        assert len(input_shape) == 2\n",
    "        self.steps = input_shape[0][1]\n",
    "\n",
    "        self.w = self.add_weight(shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "                                    initializer=self.init,\n",
    "                                    name='{}_w'.format(self.name),\n",
    "                                    regularizer=self.kernel_regularizer,\n",
    "                                    constraint=self.kernel_constraint)\n",
    "                \n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(1,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.bias_regularizer,\n",
    "                                     constraint=self.bias_constraint)\n",
    "        \n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input_tensor, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        x = input_tensor[0]\n",
    "        y = input_tensor[1]\n",
    "        mask = mask[0]\n",
    "\n",
    "        y = K.transpose(K.dot(self.w, K.transpose(y)))\n",
    "        y = K.expand_dims(y, axis=-2)\n",
    "        y = K.repeat_elements(y, self.steps, axis=1)\n",
    "        eij = K.sum(x*y, axis=-1)\n",
    "\n",
    "        if self.bias:\n",
    "            b = K.repeat_elements(self.b, self.steps, axis=0)\n",
    "            eij += b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        return a\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSum(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        assert type(input_tensor) == list\n",
    "        assert type(mask) == list\n",
    "\n",
    "        x = input_tensor[0]\n",
    "        a = input_tensor[1]\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][-1])\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAspectEmb(Layer):\n",
    "    def __init__(self, input_dim, output_dim,\n",
    "                 init='uniform', input_length=None,\n",
    "                 kernel_regularizer=None, activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 weights=None, dropout=0., **kwargs):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.init = initializers.get(init)\n",
    "        self.input_length = input_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        if 0. < self.dropout < 1.:\n",
    "            self.uses_learning_phase = True\n",
    "        self.initial_weights = weights\n",
    "        kwargs['input_shape'] = (self.input_length,)\n",
    "        kwargs['dtype'] = K.floatx()\n",
    "        super(WeightedAspectEmb, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_w'.format(self.name),\n",
    "                                 regularizer=self.kernel_regularizer,\n",
    "                                 constraint=self.kernel_constraint)\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return K.dot(x, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(Average, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "        return K.sum(x, axis=-2)/ K.sum(mask, axis=-2)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape[0:-2]+input_shape[-1:]\n",
    "    \n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxMargin(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaxMargin, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        z_s = input_tensor[0] \n",
    "        z_n = input_tensor[1]\n",
    "        r_s = input_tensor[2]\n",
    "\n",
    "        z_s = z_s / K.cast(K.epsilon() + K.sqrt(K.sum(K.square(z_s), axis=-1, keepdims=True)), K.floatx())\n",
    "        z_n = z_n / K.cast(K.epsilon() + K.sqrt(K.sum(K.square(z_n), axis=-1, keepdims=True)), K.floatx())\n",
    "        r_s = r_s / K.cast(K.epsilon() + K.sqrt(K.sum(K.square(r_s), axis=-1, keepdims=True)), K.floatx())\n",
    "\n",
    "        steps = z_n.shape[1]\n",
    "\n",
    "        pos = K.sum(z_s*r_s, axis=-1, keepdims=True)\n",
    "        pos = K.repeat_elements(pos, steps, axis=-1)\n",
    "        r_s = K.expand_dims(r_s, axis=-2)\n",
    "        r_s = K.repeat_elements(r_s, steps, axis=1)\n",
    "        neg = K.sum(z_n*r_s, axis=-1)\n",
    "\n",
    "        loss = K.cast(K.sum(K.maximum(0., (1. - pos + neg)), axis=-1, keepdims=True), K.floatx())\n",
    "        return loss\n",
    "\n",
    "    def compute_mask(self, input_tensor, mask=None):\n",
    "        return None\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
